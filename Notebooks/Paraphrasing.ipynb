{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["ElW8vkGhzC3W","zTGjnnyRy8Ql","Ffzbuo1-p2YO","7iJCCypmC2pj","v8j5m0xsFGCR","125wb6yOFKL9"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["### Checking CPU\n"],"metadata":{"id":"ElW8vkGhzC3W"}},{"cell_type":"code","source":["!lscpu"],"metadata":{"id":"dwmmvIRUzBmI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Mounting Drive\n"],"metadata":{"id":"zTGjnnyRy8Ql"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Hqfdd9Jh_YrM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"Ffzbuo1-p2YO"}},{"cell_type":"code","metadata":{"id":"4NNrlz0VCiUG"},"source":["!pip install transformers datasets fastt5"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import time\n","import torch\n","from tqdm.auto import tqdm\n","from fastT5 import export_and_get_onnx_model, get_onnx_model\n","from transformers import T5ForConditionalGeneration,T5Tokenizer"],"metadata":{"id":"zLhrcLXZ-Hhz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading Data"],"metadata":{"id":"7iJCCypmC2pj"}},{"cell_type":"code","source":["train = pd.read_csv('/content/drive/MyDrive/Inter_IIT/Datasets/qa_paras.csv')\n","train.drop(['paragraph_id', 'theme_x'], axis=1, inplace = True)\n","train.rename(columns = {'theme_y': 'theme'}, inplace=True)"],"metadata":{"id":"5-kJOjPyNhNj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gen_data = pd.read_csv('/content/drive/MyDrive/Inter_IIT/Datasets/generated_data.csv')\n","index = pd.Index(range(944, 5500))\n","gen_data = gen_data.set_index(index)\n","gen_data.drop(['ans_start', 'ans_end', 'id'], axis=1, inplace=True)\n","gen_data = gen_data[train.columns]"],"metadata":{"id":"m-XGBWnuOFZf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.concat([train, gen_data], axis=0)"],"metadata":{"id":"tx0CoyBeTG40"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading Model"],"metadata":{"id":"v8j5m0xsFGCR"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","onnx_model_path = \"/content/drive/MyDrive/Inter_IIT/Models/models_paraphrase\"\n","model_name = 'ramsrigouthamg/t5_paraphraser'\n","# model = export_and_get_onnx_model('ramsrigouthamg/t5_paraphraser') # for converting to onnx models, since the models are already saved it is not necessary to use this line of code\n","model = get_onnx_model(model_name, onnx_models_path=onnx_model_path, quantized=True) #loading saved onnx models\n","tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_paraphraser')\n","# model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_paraphraser') # for running on GPU\n","# model.to(device) # for running on GPU\n"],"metadata":{"id":"rLzFP9hZAr57"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Paraphrasing Questions\n"],"metadata":{"id":"125wb6yOFKL9"}},{"cell_type":"code","source":["def generate_ques(sentence):\n","\n","    text =  \"paraphrase: \" + sentence + \" </s>\"\n","    max_len = 256\n","\n","    encoding = tokenizer.encode_plus(text ,max_length = 512, pad_to_max_length=\"max_length\", return_tensors=\"pt\")\n","    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n","    beam_outputs = model.generate(\n","    input_ids=input_ids, attention_mask=attention_masks,\n","    do_sample=True,\n","    max_length=256,\n","    top_k=120,\n","    top_p=0.98,\n","    early_stopping=True,\n","    num_return_sequences=5\n",")\n","    \n","    final_outputs =[]\n","    for beam_output in beam_outputs:\n","      sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n","      if sent.lower() != sentence.lower() and sent not in final_outputs:\n","          final_outputs.append(sent)\n","\n","    return final_outputs"],"metadata":{"id":"721b-u3ohnsX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ques = []\n","ans = []\n","para = []\n","theme = []\n","for i in tqdm(range(df.shape[0])):\n","  final_output = generate_ques(df['question'][i])\n","  for _, final_output in enumerate(final_output):\n","    ques.append(final_output)\n","    ans.append(df['answer'][i])\n","    para.append(df['paragraph'][i])\n","    theme.append(df['theme'][i])"],"metadata":{"id":"p3Ps6X-puV40"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = {'question': ques,\n","        'answer':ans,\n","        'paragraph': para,\n","        'theme': theme,\n","        }\n","dataframe = pd.DataFrame(data)\n","dataframe.to_csv('/content/drive/MyDrive/Inter_IIT/Datasets/paraphrased_data.csv', index=False)"],"metadata":{"id":"B4TyQL8FcAIR"},"execution_count":null,"outputs":[]}]}